{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "743f27ba-9951-46bb-881c-5f3041ba8066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version 2.13.0-rc0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "print(\"tensorflow version\", tf.__version__)\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efa3fafe-17e2-4320-9af1-0a08da98fab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define image properties:\n",
    "import random\n",
    "imgDir = \"./languages\"\n",
    "targetWidth, targetHeight = 50, 50\n",
    "imageSize = (targetWidth, targetHeight)\n",
    "channels = 1  # color channels\n",
    "\n",
    "## define other constants, including command line argument defaults\n",
    "epochs = 10\n",
    "plot = True  # show plots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd0f14d4-abe1-4ddd-9c8a-21e283a598bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run interactively from /Users/andrewjumanca/GitHub/MLProjects/Neural Networks\n",
      "Load images from ./languages\n",
      "epochs: 10\n"
     ]
    }
   ],
   "source": [
    "import __main__ as main\n",
    "if hasattr(main, \"__file__\"):\n",
    "    # run as file\n",
    "    print(\"parsing command line arguments\")\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--dir\", \"-d\",\n",
    "                        help = \"directory to read images from\",\n",
    "                        default = imgDir)\n",
    "    parser.add_argument(\"--epochs\", \"-e\",\n",
    "                        help = \"how many epochs\",\n",
    "                        default= epochs)\n",
    "    parser.add_argument(\"--plot\", \"-p\",\n",
    "                        action = \"store_true\",\n",
    "                        help = \"plot a few wrong/correct results\")\n",
    "    args = parser.parse_args()\n",
    "    imgDir = args.dir\n",
    "    epochs = int(args.epochs)\n",
    "    plot = args.plot\n",
    "else:\n",
    "    # run as notebook\n",
    "    print(\"run interactively from\", os.getcwd())\n",
    "    imageDir = os.path.join(os.path.expanduser(\"~\"),\n",
    "                            \"data\", \"images\", \"text\", \"language-text-images\")\n",
    "print(\"Load images from\", imgDir)\n",
    "print(\"epochs:\", epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fa16015-c938-4e1f-96dd-ed1e1a3469fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_abbrev(filenames):\n",
    "    abbrev = []\n",
    "    for file in filenames:\n",
    "        abbrev.append(file.rpartition(\"_\")[2])\n",
    "    return abbrev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1b479b9-8453-4ff5-a541-9aea89d204c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31869 images found\n",
      "data files:\n",
      "                                filename category\n",
      "5422             liu-shouyuan_ZN-aoe.jpg       ZN\n",
      "15569  derzhavin-duhovnye-ody_RU-ahg.jpg       RU\n",
      "9428             liu-shouyuan_ZN-ahs.jpg       ZN\n",
      "25447            ocean-tramps_EN-awf.jpg       EN\n",
      "2774    tolstoy-voina-i-mir-3_RU-bbd.jpg       RU\n",
      "categories:\n",
      " category\n",
      "EN    8442\n",
      "TH    7425\n",
      "RU    6511\n",
      "ZN    5396\n",
      "DA    4095\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Prepare dataset for training model:\n",
    "\n",
    "# random sample of 1000 images\n",
    "# (1.2.3)\n",
    "filenames = os.listdir(\"languages/train\")\n",
    "\n",
    "# extract language (EN, ZN, TH, etc.)\n",
    "abbrev = find_abbrev(filenames)\n",
    "\n",
    "\n",
    "print(len(filenames), \"images found\")\n",
    "trainingResults = pd.DataFrame({\n",
    "    'filename':filenames,\n",
    "    'category':pd.Series(abbrev).str[:2]\n",
    "})\n",
    "print(\"data files:\")\n",
    "print(trainingResults.sample(5))\n",
    "nCategories = trainingResults.category.nunique()\n",
    "print(\"categories:\\n\", trainingResults.category.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3e3ce7e-e50a-4f9c-85af-2254d880f5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,\\\n",
    "    MaxPooling2D, AveragePooling2D,\\\n",
    "    Dropout,Flatten,Dense,Activation,\\\n",
    "    BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4582577-1485-4d28-be7f-6ea8c05a9d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 12, 12, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 200)               921800    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                2010      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 5)                 55        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 924185 (3.53 MB)\n",
      "Trainable params: 924185 (3.53 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Found 31869 validated image filenames belonging to 5 classes.\n",
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 16:21:21.122021: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996/996 [==============================] - 24s 24ms/step - loss: 1.1311 - accuracy: 0.6481\n",
      "Epoch 2/8\n",
      "996/996 [==============================] - 24s 24ms/step - loss: 0.5304 - accuracy: 0.8887\n",
      "Epoch 3/8\n",
      "996/996 [==============================] - 24s 24ms/step - loss: 0.3195 - accuracy: 0.9129\n",
      "Epoch 4/8\n",
      "996/996 [==============================] - 23s 23ms/step - loss: 0.2431 - accuracy: 0.9285\n",
      "Epoch 5/8\n",
      "996/996 [==============================] - 24s 24ms/step - loss: 0.2010 - accuracy: 0.9397\n",
      "Epoch 6/8\n",
      "996/996 [==============================] - 24s 24ms/step - loss: 0.1672 - accuracy: 0.9512\n",
      "Epoch 7/8\n",
      "996/996 [==============================] - 24s 24ms/step - loss: 0.1403 - accuracy: 0.9602\n",
      "Epoch 8/8\n",
      "996/996 [==============================] - 23s 23ms/step - loss: 0.1180 - accuracy: 0.9682\n",
      "7967 validation images\n",
      "7967 validation files read from languages/validation\n",
      "Found 7967 validated image filenames.\n",
      " --- Predicting on validation data ---\n",
      "  5/249 [..............................] - ETA: 6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 16:24:30.438923: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/249 [==============================] - 6s 23ms/step\n",
      "Predicted probability array shape: (7967, 5)\n",
      "Example:\n",
      " [[3.2018640e-04 5.4123101e-04 2.3980328e-04 6.0082180e-04 9.9829799e-01]\n",
      " [3.0402312e-04 5.1428506e-04 2.2664167e-04 5.4062065e-04 9.9841440e-01]\n",
      " [3.1349878e-04 5.2987598e-04 2.3430338e-04 5.7405455e-04 9.9834824e-01]\n",
      " [3.0122939e-04 5.0962961e-04 2.2437146e-04 5.3058326e-04 9.9843413e-01]\n",
      " [9.6104354e-01 1.3245153e-02 2.1530943e-02 2.6509878e-03 1.5294211e-03]]\n",
      "                               filename category  predicted\n",
      "0               chinese-laws_ZN-frt.jpg       ZN          4\n",
      "1               chinese-laws_ZN-dik.jpg       ZN          4\n",
      "2  lin-huang-tien-fei-hsieng_ZN-aac.jpg       ZN          4\n",
      "3  lin-huang-tien-fei-hsieng_ZN-abx.jpg       ZN          4\n",
      "4   aakjaer-samlede-verker-2_DA-blt.jpg       DA          0\n",
      "confusion matrix (validation)\n",
      "predicted   DA    EN    RU    TH    ZN\n",
      "category                              \n",
      "DA         804   164    45     3     3\n",
      "EN         217  1769    56     2     6\n",
      "RU          63    69  1554     3     4\n",
      "TH          10     0     4  1874    11\n",
      "ZN          11     1     4     6  1284\n",
      "Validation accuracy 0.914396887159533\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=3, strides=(2,2), padding='valid', activation='relu', input_shape=(targetWidth, targetHeight, channels)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(200,\n",
    "                activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.add(Dense(nCategories,\n",
    "                activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "## Training and validation data generator:\n",
    "trainingGenerator = ImageDataGenerator(\n",
    "    # rotation_range=15,\n",
    "    rescale=1./255#,\n",
    "    # shear_range=0.1,\n",
    "    # zoom_range=0.2,\n",
    "    # horizontal_flip=True,\n",
    "    # width_shift_range=0.1,\n",
    "    # height_shift_range=0.1\n",
    ").\\\n",
    "    flow_from_dataframe(trainingResults,\n",
    "                        os.path.join(imgDir, \"train\"),\n",
    "                        x_col='filename', y_col='category',\n",
    "                        target_size=imageSize,\n",
    "                        class_mode='categorical',\n",
    "                        color_mode=\"grayscale\",\n",
    "                        shuffle=True)\n",
    "label_map = trainingGenerator.class_indices\n",
    "## Model Training:\n",
    "history = model.fit(\n",
    "    trainingGenerator,\n",
    "    epochs=8\n",
    ")\n",
    "\n",
    "## Validation data preparation:\n",
    "validationDir = \"languages/validation\"\n",
    "\n",
    "fNames = (os.listdir(validationDir))\n",
    "\n",
    "abbrev = find_abbrev(fNames)\n",
    "\n",
    "print(len(fNames), \"validation images\")\n",
    "validationResults = pd.DataFrame({\n",
    "    'filename': fNames,\n",
    "    'category': pd.Series(abbrev).str[:2]\n",
    "})\n",
    "print(validationResults.shape[0], \"validation files read from\", validationDir)\n",
    "validationGenerator = ImageDataGenerator(rescale=1./255).\\\n",
    "    flow_from_dataframe(validationResults,\n",
    "                        os.path.join(imgDir, \"validation\"),\n",
    "                        x_col='filename',\n",
    "                        class_mode = None,\n",
    "                        target_size = imageSize,\n",
    "                        shuffle = False,\n",
    "                        # do not randomize the order!\n",
    "                        # this would clash with the file name order!\n",
    "                        color_mode=\"grayscale\"\n",
    "    ) \n",
    "\n",
    "## Make categorical prediction:\n",
    "print(\" --- Predicting on validation data ---\")\n",
    "phat = model.predict(validationGenerator)\n",
    "print(\"Predicted probability array shape:\", phat.shape)\n",
    "print(\"Example:\\n\", phat[:5])\n",
    "\n",
    "\n",
    "## Convert labels to categories:\n",
    "validationResults['predicted'] = pd.Series(np.argmax(phat, axis=-1), index=validationResults.index)\n",
    "print(validationResults.head())\n",
    "labelMap = {v: k for k, v in label_map.items()}\n",
    "validationResults[\"predicted\"] = validationResults.predicted.replace(labelMap)\n",
    "print(\"confusion matrix (validation)\")\n",
    "print(pd.crosstab(validationResults.category, validationResults.predicted))\n",
    "print(\"Validation accuracy\", np.mean(validationResults.category == validationResults.predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
